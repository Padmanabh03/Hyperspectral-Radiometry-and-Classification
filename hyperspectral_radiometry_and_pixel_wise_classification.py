# -*- coding: utf-8 -*-
"""Hyperspectral Radiometry and Pixel-Wise Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CSqsyl839f5FJX0gb0-3TRWI8kWEfUtS

#Setup and Loading WHU-Hi Dataset
"""

# Upload the Kaggle API key
from google.colab import files
files.upload()

# Make a directory for the Kaggle API key and move it there
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/

# Set the correct permissions
!chmod 600 ~/.kaggle/kaggle.json

# Install Kaggle CLI
!pip install kaggle

# Download the dataset into the Colab notebook directory
!kaggle datasets download -d rupeshkumaryadav/whu-hyperspectral-dataset

import zipfile
import os

# Extract the dataset
dataset_zip = "whu-hyperspectral-dataset.zip"
dataset_folder = "WHU_Hyperspectral_Dataset"

if not os.path.exists(dataset_folder):
    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:
        zip_ref.extractall(dataset_folder)
    print(f"Dataset extracted to: {dataset_folder}")
else:
    print(f"Dataset already extracted at: {dataset_folder}")

"""# Exploring the WHU-Hi Dataset"""

import os

# Define the base dataset path (update this if needed)
base_path = "/content/WHU_Hyperspectral_Dataset"

# List all directories and files in the dataset
for root, dirs, files in os.walk(base_path):
    print(f"Directory: {root}")
    for file in files:
        print(f" - {file}")

!pip install scipy numpy matplotlib scikit-learn spectral  # Example libraries

import numpy as np
import matplotlib.pyplot as plt
from scipy.io import loadmat
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Example paths; replace with your actual paths
data_path = '/content/drive/MyDrive/WHU_Hyperspectral_Dataset/WHU-Hi-LongKou'
image_file = '/content/WHU_Hyperspectral_Dataset/WHU-Hi-LongKou/WHU_Hi_LongKou.mat'
gt_file = '/content/WHU_Hyperspectral_Dataset/WHU-Hi-LongKou/WHU_Hi_LongKou_gt.mat'

data_mat = loadmat(image_file)   # Dictionary-like object
gt_mat   = loadmat(gt_file)

# The actual hyperspectral data might be under a specific key, e.g., 'WHU_Hi_LongKou'
# Check the keys: data_mat.keys()

hyperspectral_image = data_mat['WHU_Hi_LongKou']  # shape could be (height, width, bands)
ground_truth_labels = gt_mat['WHU_Hi_LongKou_gt'] # shape might be (height, width)

# # Check the variable names (keys) inside each .mat
# print("Keys in data_mat:", data_mat.keys())
# print("Keys in gt_mat:", gt_mat.keys())

print("Hyperspectral Image shape:", hyperspectral_image.shape)
print("Ground Truth shape:", ground_truth_labels.shape)

"""# Exploration and Visulization

##Visualize a Single Spectral Band
"""

# Let’s pick band 50 as an example
band_idx = 50
plt.figure(figsize=(6, 4))
plt.imshow(hyperspectral_image[:, :, band_idx], cmap='gray')
plt.title(f"Spectral Band {band_idx}")
plt.colorbar()
plt.show()

"""##View a Pixel’s Spectral Signature"""

# Choose a pixel (row, col)
row, col = 100, 100
pixel_spectrum = hyperspectral_image[row, col, :]
plt.figure(figsize=(6, 4))
plt.plot(pixel_spectrum)
plt.title(f"Spectrum at Pixel ({row},{col})")
plt.xlabel("Band Index")
plt.ylabel("Intensity")
plt.show()

# Flatten the ground truth to count how many pixels of each class
gt_flat = ground_truth_labels.flatten()
unique_labels, counts = np.unique(gt_flat, return_counts=True)
print("Class Distribution:")
for lbl, cnt in zip(unique_labels, counts):
    print(f"Class {lbl}: {cnt} pixels")

"""# Dummy Calibration Coefficents"""

# Suppose the sensor has B bands, each with an offset, gain, and bandwidth
H, W, B = hyperspectral_image.shape

# Fake offsets, gains, and bandwidths for illustration (random example)
offset = np.zeros(B)     # e.g., all zeros if the sensor is well-corrected
gain = np.ones(B) * 0.1  # assume each DN * 0.1 -> radiance
bandwidth = np.ones(B)   # if each band has 1 nm width (oversimplified)

# Real data would come from sensor documentation:
# offset[i], gain[i], and bandwidth[i] for each spectral band i

# Let's say the pixel's digital number (DN) = 520
# And we have a dummy offset = 20, gain = 0.1
DN_pixel = 520
dummy_offset = 20
dummy_gain = 0.1

# Calculate radiance
radiance_value = (DN_pixel - dummy_offset) * dummy_gain
print("Radiance value:", radiance_value)

radiance_cube = np.zeros_like(hyperspectral_image, dtype=float)

for i in range(B):
    # Radiance = (DN - offset) * gain
    # We do a band-by-band operation
    radiance_cube[:, :, i] = (hyperspectral_image[:, :, i] - offset[i]) * gain[i]

irradiance_map = np.zeros((H, W), dtype=float)

for i in range(B):
    # Add contribution from each band = radiance * spectral bandwidth
    irradiance_map += radiance_cube[:, :, i] * bandwidth[i]

plt.imshow(irradiance_map, cmap='jet')
plt.colorbar(label="Irradiance (approx)")
plt.title("Irradiance Map (Summed Across Bands)")
plt.show()

"""# Classification (Pixel-Wise)

---


"""

valid_mask = ground_truth_labels > 0
valid_pixels = hyperspectral_image[valid_mask, :]   # shape: (num_valid_pixels, bands)
valid_labels = ground_truth_labels[valid_mask]      # shape: (num_valid_pixels,)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    valid_pixels,
    valid_labels,
    test_size=0.3,      # 30% for testing
    random_state=42
)

# import torch
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Predict and evaluate
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Plot a Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""# Segmentation (Pixel-Wise Classification Map)"""

H, W, B = hyperspectral_image.shape
reshaped_data = hyperspectral_image.reshape(-1, B)  # shape: (H*W, B)

full_pred = clf.predict(reshaped_data)    # Predict for every pixel
classification_map = full_pred.reshape(H, W) # Reshape back to (H, W)

plt.figure(figsize=(8,6))
plt.imshow(classification_map, cmap='jet')
plt.colorbar()
plt.title("Pixel-Wise Classification Map")
plt.show()

